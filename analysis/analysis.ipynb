{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefa0348",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5e36f90",
   "metadata": {},
   "source": [
    "# Analysing Outputs\n",
    "\n",
    "1. Creating Aggregated Data For each type of experiment:\n",
    "    - Averages\n",
    "    - Ranges\n",
    "    - Context\n",
    "\n",
    "We want to output three files, one for each type, together with some summary of the data, ideally one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "mode = [\"context\", \"avg\", \"range\"]\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the paths\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "OUTPUT_PARENT_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "def load_experiment_data(experiment_type):\n",
    "    \"\"\"\n",
    "    Load the data for a specific experiment type.\n",
    "    \"\"\"\n",
    "    output_dir = OUTPUT_PARENT_DIR / experiment_type\n",
    "    if not output_dir.exists():\n",
    "        logger.error(f\"Output directory {output_dir} does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Loop through all models and load their data\n",
    "    for model_dir in output_dir.iterdir():\n",
    "        logger.info(f\"Loading data for model: {model_dir.name}\")\n",
    "        model_data = pd.DataFrame()\n",
    "        for concept in model_dir.iterdir():\n",
    "            if concept.is_dir():\n",
    "                logger.info(f\"Loading data for concept: {concept.name}\")\n",
    "                for file in concept.glob(\"*.json\"):\n",
    "                    try:\n",
    "                        data = pd.read_json(file)\n",
    "                        model_data = pd.concat([model_data, data], ignore_index=True)\n",
    "                    except ValueError as e:\n",
    "                        logger.error(f\"Error loading {file}: {e}\")\n",
    "\n",
    "load_experiment_data(\"context\")\n",
    "load_experiment_data(\"avg\")\n",
    "load_experiment_data(\"range\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
